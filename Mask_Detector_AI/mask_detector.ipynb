{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r\"D:\\competition\\\\\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels=[]\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path=os.path.join(DIRECTORY,category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path=os.path.join(path,img)\n",
    "        image=load_img(img_path,target_size=(224,244))\n",
    "        image=img_to_array(image)\n",
    "        image=preprocess_input(image)\n",
    "        \n",
    "        data.append(image)\n",
    "        labels.append(category)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the labels\n",
    "lb=LabelBinarizer()\n",
    "labels=lb.fit_transform(labels)\n",
    "labels=to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(data,dtype=\"float32\")\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX,testX,trainY,testY)=train_test_split(data,labels,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "baseModel=MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel=baseModel.output\n",
    "headModel=AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel=Flatten(name=\"flatten\")(headModel)\n",
    "headModel=Dense(128,activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable=False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "#compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.3555 - accuracy: 0.8338WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (32, 224, 244, 3).\n",
      "95/95 [==============================] - 75s 789ms/step - loss: 0.3555 - accuracy: 0.8338 - val_loss: 0.0939 - val_accuracy: 0.9805\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 74s 781ms/step - loss: 0.1137 - accuracy: 0.9605 - val_loss: 0.0592 - val_accuracy: 0.9805\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 75s 793ms/step - loss: 0.0720 - accuracy: 0.9783 - val_loss: 0.0479 - val_accuracy: 0.9792\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 76s 797ms/step - loss: 0.0690 - accuracy: 0.9743 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 79s 832ms/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.0388 - val_accuracy: 0.9779\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 75s 787ms/step - loss: 0.0461 - accuracy: 0.9835 - val_loss: 0.0334 - val_accuracy: 0.9831\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 74s 779ms/step - loss: 0.0425 - accuracy: 0.9878 - val_loss: 0.0314 - val_accuracy: 0.9883\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 74s 779ms/step - loss: 0.0402 - accuracy: 0.9855 - val_loss: 0.0310 - val_accuracy: 0.9870\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 74s 776ms/step - loss: 0.0396 - accuracy: 0.9859 - val_loss: 0.0288 - val_accuracy: 0.9870\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 74s 774ms/step - loss: 0.0316 - accuracy: 0.9895 - val_loss: 0.0256 - val_accuracy: 0.9896\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 73s 772ms/step - loss: 0.0360 - accuracy: 0.9852 - val_loss: 0.0249 - val_accuracy: 0.9935\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 74s 777ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 0.0284 - val_accuracy: 0.9896\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 73s 771ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0238 - val_accuracy: 0.9961\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 74s 774ms/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.0245 - val_accuracy: 0.9948\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 74s 776ms/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.0248 - val_accuracy: 0.9909\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 77s 816ms/step - loss: 0.0322 - accuracy: 0.9875 - val_loss: 0.0217 - val_accuracy: 0.9961\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 75s 786ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0271 - val_accuracy: 0.9883\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 74s 782ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.0204 - val_accuracy: 0.9961\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 75s 790ms/step - loss: 0.0220 - accuracy: 0.9911 - val_loss: 0.0238 - val_accuracy: 0.9935\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 75s 790ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0204 - val_accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (32, 224, 244, 3).\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       1.00      1.00      1.00       405\n",
      "without_mask       0.99      1.00      1.00       363\n",
      "\n",
      "    accuracy                           1.00       768\n",
      "   macro avg       1.00      1.00      1.00       768\n",
      "weighted avg       1.00      1.00      1.00       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "    target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving mask detector model...\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: mask_detector_improved\\assets\n"
     ]
    }
   ],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector_improved\", save_format=\"pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
